import streamlit as st
import os
import tempfile
from groq import Groq
from moviepy.editor import AudioFileClip
import re
from difflib import SequenceMatcher

# --- CONFIGURACI√ìN DE LA P√ÅGINA ---
st.set_page_config(
    page_title="Transcriptor Pro",
    page_icon="üéôÔ∏è",
    layout="wide"
)

# --- ESTILOS CSS MEJORADOS ---
st.markdown("""
<style>
    .search-result { 
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        padding: 15px; 
        border-radius: 8px; 
        margin-bottom: 12px; 
        border-left: 5px solid #ff4b4b;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        transition: all 0.3s ease;
    }
    .search-result:hover {
        transform: translateX(5px);
        box-shadow: 0 4px 8px rgba(0,0,0,0.15);
    }
    .highlight { 
        background-color: #ffeb3b; 
        font-weight: bold; 
        padding: 3px 6px; 
        border-radius: 4px; 
        color: #000;
        box-shadow: 0 1px 3px rgba(0,0,0,0.2);
    }
    .context-text {
        color: #666;
        font-style: italic;
        line-height: 1.6;
    }
    .no-results {
        background-color: #fff3cd;
        border-left: 5px solid #ffc107;
        padding: 15px;
        border-radius: 8px;
        margin: 15px 0;
    }
    .stats-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 15px;
        border-radius: 10px;
        text-align: center;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    .confidence-badge {
        display: inline-block;
        padding: 4px 8px;
        border-radius: 4px;
        font-size: 0.85em;
        font-weight: bold;
    }
    .confidence-high { background-color: #28a745; color: white; }
    .confidence-medium { background-color: #ffc107; color: black; }
    .confidence-low { background-color: #dc3545; color: white; }
</style>
""", unsafe_allow_html=True)

# --- ESTADO (SESSION STATE) ---
if "authenticated" not in st.session_state: st.session_state.authenticated = False
if "transcript_text" not in st.session_state: st.session_state.transcript_text = None
if "transcript_segments" not in st.session_state: st.session_state.transcript_segments = None
if "audio_path" not in st.session_state: st.session_state.audio_path = None
if "audio_start_time" not in st.session_state: st.session_state.audio_start_time = 0
if "chat_history" not in st.session_state: st.session_state.chat_history = []
if "search_results" not in st.session_state: st.session_state.search_results = None
if "last_search_query" not in st.session_state: st.session_state.last_search_query = ""
if "context_sentences" not in st.session_state: st.session_state.context_sentences = 3
if "enable_punctuation" not in st.session_state: st.session_state.enable_punctuation = True
if "enable_diarization" not in st.session_state: st.session_state.enable_diarization = False

# --- UTILIDADES MEJORADAS ---
def format_timestamp(seconds):
    """Formato mejorado de timestamp con horas si es necesario"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    if hours > 0:
        return f"{hours:02d}:{minutes:02d}:{secs:02d}"
    return f"{minutes:02d}:{secs:02d}"

def normalize_text(text):
    """Normaliza texto para b√∫squeda m√°s flexible"""
    # Elimina acentos, convierte a min√∫sculas
    import unicodedata
    text = ''.join(c for c in unicodedata.normalize('NFD', text) if unicodedata.category(c) != 'Mn')
    return text.lower().strip()

def fuzzy_search_score(query, text):
    """Calcula similitud para b√∫squeda difusa"""
    return SequenceMatcher(None, normalize_text(query), normalize_text(text)).ratio()

# --- SEGURIDAD (CORREGIDA) ---
def check_password():
    if st.session_state.authenticated: 
        return True
    
    st.title("üîí Acceso Restringido")
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        pwd = st.text_input("Contrase√±a", type="password", key="pwd_input")
        if st.button("Ingresar", use_container_width=True):
            try:
                if pwd == st.secrets["general"]["app_password"]:
                    st.session_state.authenticated = True
                    st.success("‚úÖ Acceso concedido")
                    st.balloons()
                    st.rerun()
                else: 
                    st.error("‚õî Contrase√±a incorrecta")
            except: 
                st.error("‚ùå Error en configuraci√≥n secrets.toml")
    return False

def get_groq_client():
    try: 
        return Groq(api_key=st.secrets["general"]["groq_api_key"])
    except: 
        return None

# --- PROCESAMIENTO DE ARCHIVOS (MEJORADO) ---
def process_audio_file(uploaded_file):
    """Procesamiento optimizado con mejor manejo de errores"""
    try:
        temp_dir = tempfile.gettempdir()
        safe_name = "".join([c for c in uploaded_file.name if c.isalnum() or c in ('.','_')]).strip()
        input_path = os.path.join(temp_dir, f"input_{safe_name}")
        output_path = os.path.join(temp_dir, f"processed_{os.path.splitext(safe_name)[0]}.mp3")

        # Guardar archivo temporal
        with open(input_path, "wb") as f:
            f.write(uploaded_file.getbuffer())

        file_size_mb = os.path.getsize(input_path) / (1024 * 1024)
        is_video = input_path.lower().endswith(('.mp4', '.m4v', '.mov', '.mkv', '.avi', '.flv'))
        
        # Mostrar informaci√≥n del archivo
        st.info(f"üìä Archivo: {file_size_mb:.1f} MB | Tipo: {'Video' if is_video else 'Audio'}")
        
        if is_video or file_size_mb > 24.0:
            status_text = f"üîÑ Optimizando archivo de {file_size_mb:.1f} MB..."
            with st.spinner(status_text):
                try:
                    clip = AudioFileClip(input_path)
                    # Configuraci√≥n optimizada para mejor calidad/tama√±o
                    clip.write_audiofile(
                        output_path, 
                        bitrate="48k",  # Aumentado para mejor calidad
                        nbytes=2, 
                        codec='libmp3lame', 
                        ffmpeg_params=["-ac", "1", "-ar", "16000"],  # Sample rate √≥ptimo para Whisper
                        logger=None
                    )
                    clip.close()
                    if os.path.exists(input_path): 
                        os.remove(input_path)
                    
                    new_size = os.path.getsize(output_path) / (1024 * 1024)
                    st.success(f"‚úÖ Comprimido: {file_size_mb:.1f} MB ‚Üí {new_size:.1f} MB")
                    return output_path
                except Exception as e:
                    st.error(f"‚ùå Error en conversi√≥n: {e}")
                    return None
        
        if input_path != output_path:
            if os.path.exists(output_path): 
                os.remove(output_path)
            os.rename(input_path, output_path)
        return output_path

    except Exception as e:
        st.error(f"‚ùå Error procesando archivo: {e}")
        return None

# --- TRANSCRIPCI√ìN MEJORADA ---
def transcribe_audio_verbose(client, file_path, model_name, enable_punctuation=True):
    """Transcripci√≥n con par√°metros optimizados"""
    try:
        size_mb = os.path.getsize(file_path) / (1024 * 1024)
        if size_mb > 25:
            st.error(f"‚ùå Archivo ({size_mb:.1f}MB) supera el l√≠mite de 25MB de Groq.")
            return None, None

        with open(file_path, "rb") as file:
            params = {
                "file": (file_path, file.read()),
                "model": model_name,
                "response_format": "verbose_json",
                "language": "es",
                "temperature": 0.0  # M√°xima precisi√≥n
            }
            
            # Prompt para mejorar precisi√≥n
            if enable_punctuation:
                params["prompt"] = "Transcripci√≥n en espa√±ol con puntuaci√≥n correcta, tildes y may√∫sculas apropiadas."
            
            transcription = client.audio.transcriptions.create(**params)
            
        return transcription.text, transcription.segments
    except Exception as e:
        st.error(f"‚ùå Error API Groq: {e}")
        return None, None

# --- CORRECCI√ìN MEJORADA ---
def correct_text_with_llama(client, raw_text):
    """Correcci√≥n m√°s inteligente con mejor prompt"""
    system_prompt = """Eres un corrector ortogr√°fico experto en espa√±ol.

TAREA:
- Corrige SOLO ortograf√≠a, tildes, puntuaci√≥n y may√∫sculas
- Mant√©n el CONTENIDO EXACTO original
- NO modifiques palabras t√©cnicas, nombres propios o t√©rminos espec√≠ficos
- NO agregues introducciones, saludos ni comentarios
- Devuelve √öNICAMENTE el texto corregido

REGLAS:
1. Conserva todas las palabras originales
2. Corrige tildes seg√∫n RAE
3. Ajusta may√∫sculas al inicio de oraciones y nombres propios
4. Mejora puntuaci√≥n para claridad
5. Respeta el orden y estructura original"""

    try:
        completion = client.chat.completions.create(
            model="llama-3.3-70b-versatile",  # Modelo m√°s potente para mejor correcci√≥n
            messages=[
                {"role": "system", "content": system_prompt}, 
                {"role": "user", "content": raw_text}
            ],
            temperature=0.1,
            max_tokens=8000
        )
        result = completion.choices[0].message.content
        
        # Limpieza de posibles prefijos
        for prefix in ["Aqu√≠ est√° el texto corregido:", "Texto corregido:", "Correcci√≥n:"]:
            result = result.replace(prefix, "")
        
        return result.strip()
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Correcci√≥n omitida: {e}")
        return raw_text

# --- B√öSQUEDA MEJORADA CON FUZZY MATCHING ---
def search_in_segments(query, segments, context_size=3, fuzzy_threshold=0.7):
    """B√∫squeda mejorada con coincidencias exactas y difusas"""
    results = []
    if not query or not segments: 
        return results
    
    query_normalized = normalize_text(query)
    
    for i, seg in enumerate(segments):
        text_normalized = normalize_text(seg['text'])
        
        # B√∫squeda exacta
        is_exact_match = query_normalized in text_normalized
        
        # B√∫squeda difusa (para errores de transcripci√≥n)
        fuzzy_score = fuzzy_search_score(query_normalized, text_normalized)
        is_fuzzy_match = fuzzy_score >= fuzzy_threshold
        
        if is_exact_match or is_fuzzy_match:
            # Contexto previo y posterior
            s_idx = max(0, i - context_size)
            prev = " ".join([s['text'] for s in segments[s_idx:i]])
            
            e_idx = min(len(segments), i + context_size + 1)
            nxt = " ".join([s['text'] for s in segments[i+1:e_idx]])
            
            # Determinar tipo de coincidencia
            match_type = "exact" if is_exact_match else "fuzzy"
            confidence = "high" if is_exact_match else ("medium" if fuzzy_score >= 0.85 else "low")
            
            results.append({
                "start": seg['start'], 
                "formatted": format_timestamp(seg['start']),
                "match": seg['text'], 
                "prev": prev, 
                "next": nxt,
                "segment_index": i,
                "match_type": match_type,
                "confidence": confidence,
                "score": fuzzy_score if is_fuzzy_match else 1.0
            })
    
    # Ordenar por puntuaci√≥n (mejores coincidencias primero)
    results.sort(key=lambda x: x['score'], reverse=True)
    return results

# --- EXPORTACI√ìN MEJORADA ---
def export_with_timestamps(segments):
    """Exporta transcripci√≥n con timestamps"""
    output = []
    for seg in segments:
        timestamp = format_timestamp(seg['start'])
        output.append(f"[{timestamp}] {seg['text']}")
    return "\n".join(output)

# --- APLICACI√ìN PRINCIPAL ---
def main_app():
    client = get_groq_client()
    if not client: 
        st.error("‚ùå No se pudo conectar con Groq API")
        st.stop()

    # --- BARRA LATERAL MEJORADA ---
    with st.sidebar:
        st.title("‚öôÔ∏è Configuraci√≥n")
        
        st.markdown("#### üéØ Modelo de Transcripci√≥n")
        model_choice = st.selectbox(
            "Selecciona modelo", 
            options=["whisper-large-v3-turbo", "whisper-large-v3"],
            help="‚Ä¢ Turbo: M√°s r√°pido, buena precisi√≥n\n‚Ä¢ V3: M√°xima precisi√≥n, m√°s lento",
            label_visibility="collapsed"
        )
        
        st.divider()
        
        st.markdown("#### üîß Opciones Avanzadas")
        st.session_state.enable_punctuation = st.checkbox(
            "‚úèÔ∏è Mejorar puntuaci√≥n autom√°tica", 
            value=True,
            help="Usa AI prompt para mejorar puntuaci√≥n durante transcripci√≥n"
        )
        
        st.divider()
        
        st.markdown("#### üîç Configuraci√≥n de B√∫squeda")
        st.session_state.context_sentences = st.slider(
            "Oraciones de contexto",
            min_value=1,
            max_value=10,
            value=3,
            help="Cantidad de oraciones antes y despu√©s"
        )
        
        enable_fuzzy = st.checkbox(
            "üéØ B√∫squeda inteligente (fuzzy)",
            value=True,
            help="Encuentra coincidencias aproximadas (√∫til para errores de transcripci√≥n)"
        )
        
        if enable_fuzzy:
            fuzzy_threshold = st.slider(
                "Sensibilidad de b√∫squeda",
                min_value=0.5,
                max_value=1.0,
                value=0.7,
                step=0.05,
                help="0.5 = muy permisivo | 1.0 = solo exactas"
            )
        else:
            fuzzy_threshold = 1.0
        
        st.divider()
        
        large_mode = st.checkbox(
            "üìÇ Modo Archivo Grande", 
            help="Para audios >40 min o >25MB"
        )
        
        st.divider()
        
        # Estad√≠sticas mejoradas
        if st.session_state.transcript_text:
            st.markdown("#### üìä Estad√≠sticas")
            words = st.session_state.transcript_text.split()
            word_count = len(words)
            char_count = len(st.session_state.transcript_text)
            segment_count = len(st.session_state.transcript_segments) if st.session_state.transcript_segments else 0
            
            # Calcular duraci√≥n total
            if st.session_state.transcript_segments:
                duration_secs = st.session_state.transcript_segments[-1]['end']
                duration_formatted = format_timestamp(duration_secs)
            else:
                duration_formatted = "N/A"
            
            st.markdown(f"""
            <div class='stats-card'>
                <div style='font-size: 28px; font-weight: bold;'>{word_count:,}</div>
                <div>Palabras</div>
            </div>
            """, unsafe_allow_html=True)
            
            st.metric("Caracteres", f"{char_count:,}")
            st.metric("Segmentos", segment_count)
            st.metric("Duraci√≥n", duration_formatted)
        
        st.divider()
        
        if st.button("üö™ Cerrar Sesi√≥n", use_container_width=True):
            st.session_state.clear()
            st.rerun()

    # --- HEADER PRINCIPAL ---
    col1, col2 = st.columns([3, 1])
    with col1:
        st.title("üéôÔ∏è Transcriptor Pro")
        st.caption("Transcripci√≥n avanzada con IA | B√∫squeda inteligente | Chat contextual")
    with col2:
        if st.session_state.transcript_text:
            st.success("‚úÖ Listo")

    # --- UPLOAD ---
    uploaded_file = st.file_uploader(
        "üìÅ Subir archivo de audio o video", 
        type=["mp3", "mp4", "wav", "m4a", "mov", "mkv", "avi", "flv", "ogg", "webm"],
        help="Formatos: MP3, MP4, WAV, M4A, MOV, MKV, AVI, FLV, OGG, WebM"
    )

    if uploaded_file:
        if st.button("üöÄ Iniciar Transcripci√≥n", type="primary", use_container_width=True):
            with st.status("‚öôÔ∏è Procesando...", expanded=True) as status:
                st.write("üîç Analizando archivo...")
                
                final_path = process_audio_file(uploaded_file)
                st.session_state.audio_path = final_path
                
                if final_path:
                    st.write(f"üéß Transcribiendo con {model_choice}...")
                    raw, segs = transcribe_audio_verbose(
                        client, 
                        final_path, 
                        model_choice,
                        st.session_state.enable_punctuation
                    )
                    
                    if raw and segs:
                        if large_mode:
                            st.info("‚ÑπÔ∏è Modo Grande: Correcci√≥n ortogr√°fica omitida")
                            st.session_state.transcript_text = raw
                        else:
                            st.write("‚ú® Mejorando ortograf√≠a con IA...")
                            st.session_state.transcript_text = correct_text_with_llama(client, raw)
                        
                        st.session_state.transcript_segments = segs
                        st.session_state.audio_start_time = 0
                        st.session_state.search_results = None
                        st.session_state.chat_history = []
                        st.session_state.last_search_query = ""
                        
                        status.update(label="‚úÖ ¬°Completado!", state="complete", expanded=False)
                        st.balloons()
                    else: 
                        status.update(label="‚ùå Error en transcripci√≥n", state="error")
                else: 
                    status.update(label="‚ùå Error procesando archivo", state="error")

    # --- REPRODUCTOR ---
    if st.session_state.audio_path and os.path.exists(st.session_state.audio_path):
        st.markdown("### üéµ Reproductor")
        st.audio(st.session_state.audio_path, start_time=st.session_state.audio_start_time)

    # --- TABS PRINCIPALES ---
    if st.session_state.transcript_text:
        tab_txt, tab_chat, tab_export = st.tabs([
            "üìù Transcripci√≥n & B√∫squeda", 
            "üí¨ Chat IA", 
            "üì• Exportar"
        ])

        # TAB 1: B√öSQUEDA MEJORADA
        with tab_txt:
            st.markdown("### üîç B√∫squeda Inteligente")
            
            with st.form(key="search_form", clear_on_submit=False):
                col_s, col_b = st.columns([5, 1])
                with col_s: 
                    search_query = st.text_input(
                        "Buscar en transcripci√≥n", 
                        value=st.session_state.last_search_query,
                        placeholder="Ej: 'innovaci√≥n tecnol√≥gica', 'resultados financieros'...",
                        label_visibility="collapsed"
                    )
                with col_b: 
                    submit_search = st.form_submit_button("üîé", use_container_width=True)
            
            if submit_search and search_query:
                st.session_state.last_search_query = search_query
                with st.spinner("Buscando..."):
                    st.session_state.search_results = search_in_segments(
                        search_query, 
                        st.session_state.transcript_segments,
                        st.session_state.context_sentences,
                        fuzzy_threshold if enable_fuzzy else 1.0
                    )

            # Mostrar resultados
            if st.session_state.last_search_query:
                if st.session_state.search_results:
                    st.success(f"‚úÖ **{len(st.session_state.search_results)}** resultados para '{st.session_state.last_search_query}'")
                    
                    for i, r in enumerate(st.session_state.search_results):
                        with st.container():
                            col_btn, col_text = st.columns([1, 8])
                            
                            with col_btn:
                                if st.button(f"‚ñ∂Ô∏è {r['formatted']}", key=f"j_{i}", use_container_width=True):
                                    st.session_state.audio_start_time = int(r['start'])
                                    st.rerun()
                            
                            with col_text:
                                # Badge de confianza
                                confidence_class = f"confidence-{r['confidence']}"
                                confidence_text = {"high": "Exacto", "medium": "Probable", "low": "Similar"}[r['confidence']]
                                
                                st.markdown(
                                    f"""<div class='search-result'>
                                        <span class='confidence-badge {confidence_class}'>{confidence_text}</span>
                                        <br><br>
                                        <span class='context-text'>...{r['prev']}</span> 
                                        <span class='highlight'>{r['match']}</span> 
                                        <span class='context-text'>{r['next']}...</span>
                                    </div>""", 
                                    unsafe_allow_html=True
                                )
                    
                    if st.button("üóëÔ∏è Limpiar b√∫squeda"):
                        st.session_state.search_results = None
                        st.session_state.last_search_query = ""
                        st.rerun()
                else:
                    st.markdown(f"""
                    <div class='no-results'>
                        <strong>‚ö†Ô∏è Sin resultados</strong><br>
                        No se encontr√≥ "<em>{st.session_state.last_search_query}</em>"<br>
                        <small>üí° Tip: {'La b√∫squeda inteligente est√° activa, pero no hay coincidencias cercanas' if enable_fuzzy else 'Activa b√∫squeda inteligente en el men√∫ lateral'}</small>
                    </div>
                    """, unsafe_allow_html=True)
            
            st.divider()
            st.markdown("### üìÑ Texto Completo")
            st.text_area(
                "Transcripci√≥n", 
                value=st.session_state.transcript_text, 
                height=400,
                label_visibility="collapsed"
            )

        # TAB 2: CHAT MEJORADO
        with tab_chat:
            st.markdown("### üí¨ Asistente IA")
            st.caption("Haz preguntas inteligentes sobre el contenido")
            
            for m in st.session_state.chat_history:
                with st.chat_message(m["role"]): 
                    st.markdown(m["content"])
            
            if p := st.chat_input("üí≠ Tu pregunta..."):
                st.session_state.chat_history.append({"role": "user", "content": p})
                with st.chat_message("user"): 
                    st.markdown(p)
                
                chat_context = st.session_state.transcript_text[:20000] if large_mode else st.session_state.transcript_text

                with st.chat_message("assistant"):
                    holder = st.empty()
                    full = ""
                    try:
                        stream = client.chat.completions.create(
                            model="llama-3.3-70b-versatile",
                            messages=[
                                {"role": "system", "content": f"""Eres un asistente experto en an√°lisis de transcripciones.

CONTEXTO DE LA TRANSCRIPCI√ìN:
{chat_context}

INSTRUCCIONES:
- Responde bas√°ndote √öNICAMENTE en el contenido de la transcripci√≥n
- Si no encuentras informaci√≥n, dilo claramente
- Cita fragmentos relevantes cuando sea apropiado
- S√© conciso pero completo
- Usa formato markdown para claridad"""},
                                {"role": "user", "content": p}
                            ], 
                            stream=True,
                            temperature=0.2,
                            max_tokens=2000
                        )
                        for chunk in stream:
                            if chunk.choices[0].delta.content:
                                full += chunk.choices[0].delta.content
                                holder.markdown(full + "‚ñå")
                        holder.markdown(full)
                        st.session_state.chat_history.append({"role": "assistant", "content": full})
                    except Exception as e: 
                        st.error(f"‚ùå Error: {e}")
            
            if st.session_state.chat_history:
                if st.button("üóëÔ∏è Limpiar chat"):
                    st.session_state.chat_history = []
                    st.rerun()

        # TAB 3: EXPORTACI√ìN
        with tab_export:
            st.markdown("### üì• Exportar Transcripci√≥n")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("#### Formato Simple")
                st.download_button(
                    "üìÑ Texto plano (.txt)", 
                    st.session_state.transcript_text, 
                    "transcripcion.txt",
                    use_container_width=True
                )
                st.download_button(
                    "üìù Markdown (.md)", 
                    st.session_state.transcript_text, 
                    "transcripcion.md",
                    mime="text/markdown",
                    use_container_width=True
                )
            
            with col2:
                st.markdown("#### Con Timestamps")
                timestamped = export_with_timestamps(st.session_state.transcript_segments)
                st.download_button(
                    "‚è±Ô∏è Con marcas de tiempo (.txt)", 
                    timestamped, 
                    "transcripcion_timestamps.txt",
                    use_container_width=True
                )
            
            st.divider()
            st.markdown("#### Vista Previa con Timestamps")
            st.code(timestamped[:1000] + "..." if len(timestamped) > 1000 else timestamped, language="text")

if __name__ == "__main__":
    if check_password(): 
        main_app()
